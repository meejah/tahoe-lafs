name: CI

on:
  push:
    branches:
      - "master"
  pull_request:

# Control to what degree jobs in this workflow will run concurrently with
# other instances of themselves.
#
# https://docs.github.com/en/actions/learn-github-actions/workflow-syntax-for-github-actions#concurrency
concurrency:
  # We want every revision on master to run the workflow completely.
  # "head_ref" is not set for the "push" event but it is set for the
  # "pull_request" event.  If it is set then it is the name of the branch and
  # we can use it to make sure each branch has only one active workflow at a
  # time.  If it is not set then we can compute a unique string that gives
  # every master/push workflow its own group.
  group: "${{ github.head_ref || format('{0}-{1}', github.run_number, github.run_attempt) }}"

  # Then, we say that if a new workflow wants to start in the same group as a
  # running workflow, the running workflow should be cancelled.
  cancel-in-progress: true

env:
  # Tell Hypothesis which configuration we want it to use.
  TAHOE_LAFS_HYPOTHESIS_PROFILE: "ci"

jobs:

  coverage:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os:
          - windows-latest
        python-version:
          - "3.10"

    steps:
      # See https://github.com/actions/checkout. A fetch-depth of 0
      # fetches all tags and branches.
      - name: Check out Tahoe-LAFS sources
        uses: actions/checkout@v2
        with:
          fetch-depth: 0

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v2
        with:
          python-version: ${{ matrix.python-version }}

      # To use pip caching with GitHub Actions in an OS-independent
      # manner, we need `pip cache dir` command, which became
      # available since pip v20.1+.  At the time of writing this,
      # GitHub Actions offers pip v20.3.3 for both ubuntu-latest and
      # windows-latest, and pip v20.3.1 for macos-latest.
      - name: Get pip cache directory
        id: pip-cache
        run: |
          echo "::set-output name=dir::$(pip cache dir)"

      # See https://github.com/actions/cache
      - name: Use pip cache
        uses: actions/cache@v2
        with:
          path: ${{ steps.pip-cache.outputs.dir }}
          key: ${{ runner.os }}-pip-${{ hashFiles('**/setup.py') }}
          restore-keys: |
            ${{ runner.os }}-pip-

      - name: Install Python packages
        run: |
          pip install --upgrade codecov tox tox-gh-actions setuptools
          pip list

      - name: Display tool versions
        run: python misc/build_helpers/show-tool-versions.py

      - name: Run tox for corresponding Python version
        run: python -m tox

      - name: Upload eliot.log
        uses: actions/upload-artifact@v1
        with:
          name: eliot.log
          path: eliot.log

      - name: Upload trial log
        uses: actions/upload-artifact@v1
        with:
          name: test.log
          path: _trial_temp/test.log

      # Upload this job's coverage data to Coveralls.  While there is a GitHub
      # Action for this, as of Jan 2021 it does not support Python coverage
      # files - only lcov files.  Therefore, we use coveralls-python, the
      # coveralls.io-supplied Python reporter, for this.
      - name: "Report Coverage to Coveralls"
        run: |
          pip3 install --upgrade coveralls==3.0.1
          python3 -m coveralls
        env:
          # Some magic value required for some magic reason.
          GITHUB_TOKEN: "${{ secrets.GITHUB_TOKEN }}"
          # Help coveralls identify our project.
          COVERALLS_REPO_TOKEN: "JPf16rLB7T2yjgATIxFzTsEgMdN1UNq6o"
          # Every source of coverage reports needs a unique "flag name".
          # Construct one by smashing a few variables from the matrix together
          # here.
          COVERALLS_FLAG_NAME: "run-${{ matrix.os }}-${{ matrix.python-version }}"
          # Mark the data as just one piece of many because we have more than
          # one instance of this job (Windows, macOS) which collects and
          # reports coverage.  This is necessary to cause Coveralls to merge
          # multiple coverage results into a single report.  Note the merge
          # only happens when we "finish" a particular build, as identified by
          # its "build_num" (aka "service_number").
          COVERALLS_PARALLEL: true
